Why Parquet File is Bigger for Small Data
  Your original CSV: 42 bytes
  Parquet versions: ~2 KB even with compression.
Reason â†’ Parquet is not just raw data; itâ€™s a self-describing binary format that stores:
Columnar data blocks (even if tiny, each has a fixed structure).
Metadata & schema:
    Column names
    Data types
    Encoding info
    Row group & page offsets
Compression metadata (codec type, dictionary usage, etc.)
Footer with column statistics (min, max, null counts).

ðŸ“Œ For tiny files, the overhead of Parquet metadata is much larger than the actual data,
so even â€œcompressedâ€ files can look inflated.
2. Why Metadata Adds Size
    In CSV: thereâ€™s no extra metadata â€” just raw text + delimiter.
    In Parquet:
        File begins with data pages (compressed or uncompressed).
        Ends with footer (schema, offsets, stats).
        Footer size is fixed overhead â€” so for small data, percentage-wise itâ€™s huge.
    Example:
        Data: 42 bytes
        Metadata: ~2 KB
        Result: File size â‰ˆ 2 KB (data barely matters).

3. Slicing & Dicing Within a Compressed File
Parquetâ€™s magic trick:
    Data is divided into row groups â†’ each row group into column chunks â†’ each chunk into pages.
    Compression is applied per page, not on the whole file.
    This means:
        You can read only needed columns without decompressing the entire file.
        You can read only relevant row groups if filter conditions (predicate pushdown) match.
    In CSV or gzipâ€™d CSV:
        You must decompress the entire file to read even one column.

4. Why Large Files Benefit
For your 40 MB, 1 million row file:
    Parquet can:
    Store each column separately (better compression ratio).
    Use dictionary encoding for repeated values.
    Apply per-column compression (e.g., Snappy, GZIP).
    Result:
    40 MB CSV â†’ 6 MB Parquet (compressed)
    Overhead (metadata) is tiny compared to total data size.

5. Size Behavior Summary

| File Size            | CSV Size | Parquet (no compression) | Parquet + GZIP | Why                          |
| -------------------- | -------- | ------------------------ | -------------- | ---------------------------- |
| **Small** (42 bytes) | 42 B     | \~2 KB                   | \~2.6 KB       | Metadata overhead dominates  |
| **Large** (40 MB)    | 40 MB    | \~10â€“15 MB               | \~6 MB         | Compression savings dominate |


Key Takeaways
    Small files: Parquet looks â€œinflatedâ€ because metadata > data.
    Large files: Parquet shines because columnar compression drastically reduces size.
    Slicing/Dicing: Parquetâ€™s per-column, per-page compression allows selective reads â€” unlike CSV, where you must read everything.
